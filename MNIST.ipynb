{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf1adf2-759b-4011-b196-204a226a932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 15:35:59.792843: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-29 15:36:00.561703: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-29 15:36:00.566241: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-29 15:36:06.374757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 15:36:18.267345: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2322c3-16f8-4e86-a4c3-670dbd8d6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655f6ec2-8f98-4cc8-a163-539dd2851eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_MNIST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 7, 7, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 2, 2, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116074 (453.41 KB)\n",
      "Trainable params: 116074 (453.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 12:06:37.481357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 222 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:1d:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape =(28,28,1))\n",
    "x = layers.Conv2D(32,5,strides = (2,2),activation=\"relu\", padding=\"same\")(inputs)\n",
    "x = layers.Conv2D(32,5,activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(64,3,strides = (2,2), activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.Conv2D(64,3, activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs,outputs, name = \"CNN_MNIST\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8a4774-0713-46db-8403-b6952875eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.Adam(0.001),\n",
    "              loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "              metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b18526-adc5-4e8e-8391-d46bc66c61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 12:09:17.593905: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 179.44MiB (rounded to 188160000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-08-22 12:09:17.593944: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-08-22 12:09:17.593969: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 32, Chunks in use: 32. 8.0KiB allocated for chunks. 8.0KiB in use in bin. 1.4KiB client-requested in use in bin.\n",
      "2023-08-22 12:09:17.593974: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.593978: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-08-22 12:09:17.593983: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 4, Chunks in use: 3. 12.5KiB allocated for chunks. 9.8KiB in use in bin. 9.4KiB client-requested in use in bin.\n",
      "2023-08-22 12:09:17.593992: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 5.0KiB client-requested in use in bin.\n",
      "2023-08-22 12:09:17.593996: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.593999: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594004: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 58.8KiB allocated for chunks. 58.8KiB in use in bin. 58.6KiB client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594009: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 5, Chunks in use: 4. 442.2KiB allocated for chunks. 372.0KiB in use in bin. 372.0KiB client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594013: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 272.0KiB allocated for chunks. 272.0KiB in use in bin. 272.0KiB client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594017: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594020: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594024: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594027: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594031: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594034: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594038: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594041: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594045: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594050: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 1. 221.97MiB allocated for chunks. 221.97MiB in use in bin. 179.44MiB client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594054: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-22 12:09:17.594061: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 179.44MiB was 128.00MiB, Chunk State: \n",
      "2023-08-22 12:09:17.594064: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 233570304\n",
      "2023-08-22 12:09:17.594070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000000 of size 1280 next 1\n",
      "2023-08-22 12:09:17.594074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000500 of size 256 next 2\n",
      "2023-08-22 12:09:17.594077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000600 of size 256 next 3\n",
      "2023-08-22 12:09:17.594079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000700 of size 256 next 5\n",
      "2023-08-22 12:09:17.594082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000800 of size 256 next 6\n",
      "2023-08-22 12:09:17.594085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000900 of size 256 next 4\n",
      "2023-08-22 12:09:17.594087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000a00 of size 256 next 7\n",
      "2023-08-22 12:09:17.594090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000b00 of size 256 next 12\n",
      "2023-08-22 12:09:17.594092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000c00 of size 256 next 10\n",
      "2023-08-22 12:09:17.594095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000d00 of size 256 next 11\n",
      "2023-08-22 12:09:17.594097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000e00 of size 256 next 17\n",
      "2023-08-22 12:09:17.594100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396000f00 of size 256 next 15\n",
      "2023-08-22 12:09:17.594102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001000 of size 256 next 16\n",
      "2023-08-22 12:09:17.594105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001100 of size 256 next 19\n",
      "2023-08-22 12:09:17.594107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001200 of size 256 next 20\n",
      "2023-08-22 12:09:17.594110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001300 of size 256 next 23\n",
      "2023-08-22 12:09:17.594113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001400 of size 512 next 24\n",
      "2023-08-22 12:09:17.594115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001600 of size 256 next 25\n",
      "2023-08-22 12:09:17.594118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001700 of size 256 next 27\n",
      "2023-08-22 12:09:17.594121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001800 of size 256 next 30\n",
      "2023-08-22 12:09:17.594123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001900 of size 256 next 28\n",
      "2023-08-22 12:09:17.594126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001a00 of size 256 next 29\n",
      "2023-08-22 12:09:17.594128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001b00 of size 256 next 33\n",
      "2023-08-22 12:09:17.594131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001c00 of size 256 next 34\n",
      "2023-08-22 12:09:17.594133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001d00 of size 256 next 35\n",
      "2023-08-22 12:09:17.594136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001e00 of size 256 next 36\n",
      "2023-08-22 12:09:17.594138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396001f00 of size 256 next 37\n",
      "2023-08-22 12:09:17.594141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396002000 of size 256 next 39\n",
      "2023-08-22 12:09:17.594143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396002100 of size 256 next 40\n",
      "2023-08-22 12:09:17.594146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396002200 of size 256 next 41\n",
      "2023-08-22 12:09:17.594148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396002300 of size 256 next 8\n",
      "2023-08-22 12:09:17.594152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396002400 of size 3328 next 9\n",
      "2023-08-22 12:09:17.594155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396003100 of size 102400 next 45\n",
      "2023-08-22 12:09:17.594157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d39601c100 of size 102400 next 14\n",
      "2023-08-22 12:09:17.594160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396035100 of size 102400 next 13\n",
      "2023-08-22 12:09:17.594163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d39604e100 of size 73728 next 18\n",
      "2023-08-22 12:09:17.594165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396060100 of size 3328 next 42\n",
      "2023-08-22 12:09:17.594168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396060e00 of size 3328 next 43\n",
      "2023-08-22 12:09:17.594170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396061b00 of size 256 next 44\n",
      "2023-08-22 12:09:17.594173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396061c00 of size 256 next 46\n",
      "2023-08-22 12:09:17.594175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396061d00 of size 256 next 47\n",
      "2023-08-22 12:09:17.594178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 14d396061e00 of size 2816 next 32\n",
      "2023-08-22 12:09:17.594180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396062900 of size 5120 next 31\n",
      "2023-08-22 12:09:17.594183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396063d00 of size 60160 next 38\n",
      "2023-08-22 12:09:17.594186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 14d396072800 of size 71936 next 22\n",
      "2023-08-22 12:09:17.594188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d396084100 of size 147456 next 21\n",
      "2023-08-22 12:09:17.594192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d3960a8100 of size 131072 next 26\n",
      "2023-08-22 12:09:17.594195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d3960c8100 of size 232750848 next 18446744073709551615\n",
      "2023-08-22 12:09:17.594197: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-08-22 12:09:17.594202: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 32 Chunks of size 256 totalling 8.0KiB\n",
      "2023-08-22 12:09:17.594205: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 512 totalling 512B\n",
      "2023-08-22 12:09:17.594208: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-08-22 12:09:17.594211: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 3328 totalling 9.8KiB\n",
      "2023-08-22 12:09:17.594214: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5120 totalling 5.0KiB\n",
      "2023-08-22 12:09:17.594217: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 60160 totalling 58.8KiB\n",
      "2023-08-22 12:09:17.594221: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 73728 totalling 72.0KiB\n",
      "2023-08-22 12:09:17.594224: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 102400 totalling 300.0KiB\n",
      "2023-08-22 12:09:17.594227: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2023-08-22 12:09:17.594231: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 147456 totalling 144.0KiB\n",
      "2023-08-22 12:09:17.594234: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 232750848 totalling 221.97MiB\n",
      "2023-08-22 12:09:17.594237: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 222.68MiB\n",
      "2023-08-22 12:09:17.594241: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 233570304 memory_limit_: 233570304 available bytes: 0 curr_region_allocation_bytes_: 467140608\n",
      "2023-08-22 12:09:17.594249: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       233570304\n",
      "InUse:                       233495552\n",
      "MaxInUse:                    233495552\n",
      "NumAllocs:                          76\n",
      "MaxAllocSize:                232750848\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-08-22 12:09:17.594255: W tensorflow/tsl/framework/bfc_allocator.cc:497] *********************************************************************************xxxxxxxxxxxxxxxxxxx\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs = 5, validation_data = [x_test, y_test], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa176153-e318-4096-930c-8d6481694d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a698346-1c2e-4c7e-891d-e1d96c40aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[1])\n",
    "print(y_test[1])\n",
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f4fd8-e847-4cf3-8fc0-3603783a1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 250\n",
    "plt.imshow(x_test[index])\n",
    "print(y_test[np.argmax(prediction[index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8632ee-01bf-47cd-89e6-a91c612171dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save model to SavedModel format\n",
    "tf.saved_model.save(model, \"./models/MNIST_model\")\n",
    "\n",
    " # load the saved_model using low-level API\n",
    "model_path = \"models/MNIST_model\"\n",
    "m = tf.saved_model.load(model_path)\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "tfm = tf.function(lambda x: m(x))  # full model                                                  \n",
    "tfm = tfm.get_concrete_function(tf.TensorSpec(m.signatures['serving_default'].inputs[0].shape.as_list(), m.signatures['serving_default'].inputs[0].dtype.name))   \n",
    "frozen_func = convert_variables_to_constants_v2(tfm)                                                                                                                              \n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph, logdir=\"./\", name=\"MNIST.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5a7ed-c1d8-4d90-a2bd-f9a2f1aa8ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
